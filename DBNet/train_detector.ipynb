{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d903f-536e-493d-b4e0-73b0ddad8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# 0. 라이브러리 임포트  학습용 코드\n",
    "# ====================================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 1: 텍스트 탐지 모듈 (DBNet) 및 손실 함수 (DBLoss)\n",
    "# ====================================================================================\n",
    "\n",
    "# 1-1. DBNet 아키텍처\n",
    "class MobileNetV3_Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super().__init__()\n",
    "        features = mobilenet_v3_large(pretrained=pretrained).features\n",
    "        self.out_layers = nn.ModuleList([\n",
    "            features[0:4], features[4:7], features[7:13], features[13:17]\n",
    "        ])\n",
    "        self.out_channels = [40, 80, 160, 960]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [layer(x) for layer in self.out_layers]\n",
    "        return outputs\n",
    "\n",
    "class DB_FPN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=256):\n",
    "        super().__init__()\n",
    "        self.in_convs = nn.ModuleList([nn.Conv2d(c, out_channels, 1, bias=False) for c in in_channels])\n",
    "        self.out_convs = nn.ModuleList([nn.Conv2d(out_channels, out_channels // 4, 3, padding=1, bias=False) for _ in in_channels])\n",
    "\n",
    "    def forward(self, features):\n",
    "        inner_features = [conv(f) for conv, f in zip(self.in_convs, features)]\n",
    "        p4 = inner_features[3]\n",
    "        p3 = F.interpolate(p4, scale_factor=2) + inner_features[2]\n",
    "        p2 = F.interpolate(p3, scale_factor=2) + inner_features[1]\n",
    "        p1 = F.interpolate(p2, scale_factor=2) + inner_features[0]\n",
    "        \n",
    "        final_features = [\n",
    "            self.out_convs[0](p1),\n",
    "            self.out_convs[1](F.interpolate(p2, scale_factor=2)),\n",
    "            self.out_convs[2](F.interpolate(p3, scale_factor=4)),\n",
    "            self.out_convs[3](F.interpolate(p4, scale_factor=8)),\n",
    "        ]\n",
    "        return torch.cat(final_features, dim=1)\n",
    "\n",
    "class DB_Head(nn.Module):\n",
    "    def __init__(self, in_channels=256):\n",
    "        super().__init__()\n",
    "        self.prob_conv = nn.Sequential(nn.Conv2d(in_channels, in_channels // 4, 3, padding=1), nn.ReLU(), nn.ConvTranspose2d(in_channels // 4, 1, 2, 2))\n",
    "        self.thresh_conv = nn.Sequential(nn.Conv2d(in_channels, in_channels // 4, 3, padding=1), nn.ReLU(), nn.ConvTranspose2d(in_channels // 4, 1, 2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        prob_map = torch.sigmoid(self.prob_conv(x))\n",
    "        thresh_map = torch.sigmoid(self.thresh_conv(x))\n",
    "        return prob_map, thresh_map\n",
    "\n",
    "class DBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = MobileNetV3_Backbone()\n",
    "        self.fpn = DB_FPN(in_channels=self.backbone.out_channels)\n",
    "        self.head = DB_Head(in_channels=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.fpn(self.backbone(x)))\n",
    "\n",
    "# 1-2. DBNet 손실 함수\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, pred, target, mask):\n",
    "        pred, target = pred * mask, target * mask\n",
    "        intersection = (pred * target).sum()\n",
    "        union = pred.sum() + target.sum() + self.eps\n",
    "        return 1 - (2 * intersection / union)\n",
    "\n",
    "class DBLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=10.0, k=50):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta, self.k = alpha, beta, k\n",
    "        self.bce_loss = nn.BCELoss(reduction='none')\n",
    "        self.dice_loss = DiceLoss()\n",
    "\n",
    "    def forward(self, pred_maps, gt_maps):\n",
    "        pred_prob, pred_thresh = pred_maps\n",
    "        gt_prob, gt_prob_mask, gt_thresh, gt_thresh_mask = gt_maps\n",
    "\n",
    "        # L_s (BCE + Dice)\n",
    "        bce_prob_loss = (self.bce_loss(pred_prob, gt_prob) * gt_prob_mask).mean()\n",
    "        dice_prob_loss = self.dice_loss(pred_prob, gt_prob, gt_prob_mask)\n",
    "        loss_s = bce_prob_loss + dice_prob_loss\n",
    "\n",
    "        # L_b (Dice on DB map)\n",
    "        db_map = 1 / (1 + torch.exp(-self.k * (pred_prob - pred_thresh)))\n",
    "        loss_b = self.dice_loss(db_map, gt_prob, gt_prob_mask)\n",
    "\n",
    "        # L_t (L1 on Threshold map)\n",
    "        loss_t = (torch.abs(pred_thresh - gt_thresh) * gt_thresh_mask).sum() / (gt_thresh_mask.sum() + 1e-6)\n",
    "\n",
    "        return loss_s + self.alpha * loss_b + self.beta * loss_t\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 2: 텍스트 인식 모듈 (CRNN)\n",
    "# ====================================================================================\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_chars, rnn_hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(True), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d((2, 1), (2, 1)),\n",
    "            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU(True), nn.MaxPool2d((2, 1), (2, 1)),\n",
    "            nn.Conv2d(512, 512, 2, 1, 0), nn.BatchNorm2d(512), nn.ReLU(True)\n",
    "        )\n",
    "        self.rnn = nn.LSTM(512, rnn_hidden_size, bidirectional=True, num_layers=2)\n",
    "        self.classifier = nn.Linear(rnn_hidden_size * 2, num_chars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_features = self.cnn(x).squeeze(2).permute(2, 0, 1)\n",
    "        rnn_output, _ = self.rnn(conv_features)\n",
    "        return self.classifier(rnn_output)\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 3: 데이터 시뮬레이션 (더미 데이터 생성)\n",
    "# ====================================================================================\n",
    "def generate_dummy_ocr_image(path=\"dummy_ocr_test.png\"):\n",
    "    \"\"\"추론 테스트를 위한 더미 이미지 생성\"\"\"\n",
    "    image = np.ones((600, 800, 3), np.uint8) * 255\n",
    "    cv2.putText(image, 'hello ocr 123', (100, 200), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 5)\n",
    "    cv2.putText(image, 'pytorch', (150, 400), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 5)\n",
    "    cv2.imwrite(path, image)\n",
    "    return path\n",
    "\n",
    "def generate_dummy_training_batch(batch_size, img_size, character_list):\n",
    "    \"\"\"학습 과정을 시뮬레이션하기 위한 더미 배치 데이터 생성\"\"\"\n",
    "    # 1. 탐지 모델용 데이터\n",
    "    det_images = torch.rand(batch_size, 3, img_size, img_size)\n",
    "    gt_prob = torch.rand(batch_size, 1, img_size, img_size) > 0.8\n",
    "    gt_prob_mask = torch.ones(batch_size, 1, img_size, img_size)\n",
    "    gt_thresh = torch.rand(batch_size, 1, img_size, img_size)\n",
    "    gt_thresh_mask = gt_prob.clone()\n",
    "    db_gts = (gt_prob.float(), gt_prob_mask.float(), gt_thresh.float(), gt_thresh_mask.float())\n",
    "    \n",
    "    # 2. 인식 모델용 데이터 (잘라낸 단어 이미지라고 가정)\n",
    "    rec_images = torch.rand(batch_size, 3, 32, 100) # (B, C, H, W)\n",
    "    \n",
    "    # 더미 텍스트 생성\n",
    "    gt_texts = []\n",
    "    for _ in range(batch_size):\n",
    "        length = np.random.randint(3, 10)\n",
    "        text = \"\".join(np.random.choice(list(character_list), length))\n",
    "        gt_texts.append(text)\n",
    "        \n",
    "    return det_images, db_gts, rec_images, gt_texts\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 4: OCR 파이프라인 (추론용)\n",
    "# ====================================================================================\n",
    "class OCR_Pipeline:\n",
    "    def __init__(self, detector, recognizer, char_map):\n",
    "        self.detector = detector\n",
    "        self.recognizer = recognizer\n",
    "        self.idx_to_char = {i + 1: char for i, char in enumerate(char_map)}\n",
    "        \n",
    "        self.detector.eval()\n",
    "        self.recognizer.eval()\n",
    "\n",
    "    def _get_cropped_image(self, image, box):\n",
    "        w = max(np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[2] - box[3]))\n",
    "        h = max(np.linalg.norm(box[0] - box[3]), np.linalg.norm(box[1] - box[2]))\n",
    "        dst_pts = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype=np.float32)\n",
    "        M = cv2.getPerspectiveTransform(box.astype(np.float32), dst_pts)\n",
    "        return cv2.warpPerspective(image, M, (int(w), int(h)))\n",
    "\n",
    "    def _ctc_greedy_decode(self, preds):\n",
    "        preds_idx = preds.argmax(dim=2).transpose(1, 0).contiguous().view(-1)\n",
    "        decoded_text, last_char_idx = [], 0\n",
    "        for idx in preds_idx:\n",
    "            if idx.item() == 0 or idx.item() == last_char_idx:\n",
    "                last_char_idx = idx.item() if idx.item() != 0 else 0\n",
    "                continue\n",
    "            decoded_text.append(self.idx_to_char.get(idx.item(), ''))\n",
    "            last_char_idx = idx.item()\n",
    "        return \"\".join(decoded_text)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        img_h, img_w = image.shape[:2]\n",
    "        \n",
    "        det_input = cv2.resize(image, (640, 640))\n",
    "        det_input = torch.from_numpy(det_input).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prob_map, _ = self.detector(det_input)\n",
    "            \n",
    "            # 후처리\n",
    "            binary_map = (prob_map.squeeze().numpy() > 0.3).astype(np.uint8)\n",
    "            contours, _ = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            scale_x, scale_y = img_w / 640, img_h / 640\n",
    "            results = []\n",
    "            for contour in contours:\n",
    "                if cv2.contourArea(contour) < 100: continue\n",
    "                box = np.intp(cv2.boxPoints(cv2.minAreaRect(contour)) * np.array([scale_x, scale_y]))\n",
    "                \n",
    "                cropped_img = self._get_cropped_image(image, box)\n",
    "                if cropped_img.shape[0] < 10 or cropped_img.shape[1] < 10: continue\n",
    "\n",
    "                rec_input = cv2.resize(cropped_img, (100, 32))\n",
    "                rec_input = torch.from_numpy(rec_input).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "                \n",
    "                preds = self.recognizer(rec_input)\n",
    "                text = self._ctc_greedy_decode(preds)\n",
    "                results.append({'box': box.tolist(), 'text': text})\n",
    "        \n",
    "        return results, image\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 5: 메인 실행 블록 (학습 시뮬레이션 및 추론)\n",
    "# ====================================================================================\n",
    "if __name__ == '__main__':\n",
    "    # --- 1. 모델 및 하이퍼파라미터 설정 ---\n",
    "    print(\"Step 1: 모델 및 설정 초기화...\")\n",
    "    CHARACTER_SET = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "    NUM_CLASSES = len(CHARACTER_SET) + 1 # +1 for CTC blank token\n",
    "    \n",
    "    detector = DBNet()\n",
    "    recognizer = CRNN(num_chars=NUM_CLASSES)\n",
    "    \n",
    "    db_loss_fn = DBLoss()\n",
    "    ctc_loss_fn = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    \n",
    "    optimizer_det = torch.optim.Adam(detector.parameters(), lr=1e-4)\n",
    "    optimizer_rec = torch.optim.Adam(recognizer.parameters(), lr=1e-4)\n",
    "    \n",
    "    # --- 2. 더미 학습 과정 시뮬레이션 ---\n",
    "    print(\"\\nStep 2: 더미 학습 과정 시뮬레이션 시작...\")\n",
    "    num_steps = 5\n",
    "    for i in range(num_steps):\n",
    "        # 더미 데이터 생성\n",
    "        det_imgs, db_gts, rec_imgs, rec_gts = generate_dummy_training_batch(4, 640, CHARACTER_SET)\n",
    "        \n",
    "        # --- 탐지 모델 학습 ---\n",
    "        detector.train()\n",
    "        optimizer_det.zero_grad()\n",
    "        pred_maps = detector(det_imgs)\n",
    "        loss_det = db_loss_fn(pred_maps, db_gts)\n",
    "        loss_det.backward()\n",
    "        optimizer_det.step()\n",
    "        \n",
    "        # --- 인식 모델 학습 ---\n",
    "        # 실제로는 탐지된 영역을 잘라 학습하지만, 여기서는 독립적으로 시뮬레이션\n",
    "        recognizer.train()\n",
    "        optimizer_rec.zero_grad()\n",
    "        preds_rec = recognizer(rec_imgs) # (SeqLen, Batch, NumClasses)\n",
    "        \n",
    "        # CTCLoss를 위한 데이터 준비\n",
    "        log_probs = F.log_softmax(preds_rec, dim=2)\n",
    "        input_lengths = torch.full(size=(4,), fill_value=preds_rec.size(0), dtype=torch.long)\n",
    "        \n",
    "        char_to_idx = {char: i + 1 for i, char in enumerate(CHARACTER_SET)}\n",
    "        targets = torch.cat([torch.tensor([char_to_idx[c] for c in text], dtype=torch.long) for text in rec_gts])\n",
    "        target_lengths = torch.tensor([len(text) for text in rec_gts], dtype=torch.long)\n",
    "        \n",
    "        loss_rec = ctc_loss_fn(log_probs, targets, input_lengths, target_lengths)\n",
    "        loss_rec.backward()\n",
    "        optimizer_rec.step()\n",
    "        \n",
    "        print(f\"  Step {i+1}/{num_steps} - Detector Loss: {loss_det.item():.4f}, Recognizer Loss: {loss_rec.item():.4f}\")\n",
    "\n",
    "    print(\"더미 학습 완료.\")\n",
    "    \n",
    "    # --- 3. 추론 파이프라인 실행 ---\n",
    "    print(\"\\nStep 3: 추론 파이프라인 실행...\")\n",
    "    # '학습된' 모델로 파이프라인 교체\n",
    "    pipeline = OCR_Pipeline(detector, recognizer, CHARACTER_SET)\n",
    "    \n",
    "    # 테스트 이미지 생성 및 예측\n",
    "    dummy_img_path = generate_dummy_ocr_image()\n",
    "    ocr_results, result_image = pipeline.predict(dummy_img_path)\n",
    "    \n",
    "    print(\"\\n--- 최종 OCR 결과 ---\")\n",
    "    if not ocr_results:\n",
    "        print(\"탐지된 텍스트가 없습니다.\")\n",
    "    else:\n",
    "        for result in ocr_results:\n",
    "            # 결과 시각화\n",
    "            box = np.array(result['box'], dtype=np.intp)\n",
    "            cv2.drawContours(result_image, [box], 0, (0, 255, 0), 2)\n",
    "            # 텍스트 쓰기\n",
    "            cv2.putText(result_image, result['text'], (box[0][0], box[0][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            print(f\"Box: {result['box']}, Text: '{result['text']}'\")\n",
    "            \n",
    "    # 결과 이미지 저장\n",
    "    result_img_path = \"final_ocr_result.png\"\n",
    "    cv2.imwrite(result_img_path, result_image)\n",
    "    print(f\"\\n결과 이미지가 '{result_img_path}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6308b-405f-464d-aa97-5efdfa47cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45835e4c-8f4b-4a57-b654-c28fa2f7d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3a4b8-4380-4673-b2e9-2112e902418e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치: cuda\n",
      "사전 학습된 MobileNetV3 가중치를 사용합니다.\n",
      "데이터 로더를 준비합니다...\n",
      "어노테이션 파일을 로드하고 데이터를 전처리합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23716\\595093342.py:211: UserWarning: Argument(s) 'always_apply' are not valid for transform Resize\n",
      "  A.Resize(size, size, always_apply=True),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 19569개의 유효한 이미지를 찾았습니다.\n",
      "모델과 옵티마이저를 준비합니다...\n",
      "학습을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|████████████████████████████████████████| 4893/4893 [20:19<00:00,  4.01it/s, loss=1.8234, lr=1.0e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 완료, 평균 손실: 2.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|████████████████████████████████████████| 4893/4893 [18:42<00:00,  4.36it/s, loss=2.3973, lr=1.0e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 완료, 평균 손실: 1.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|████████████████████████████████████████| 4893/4893 [18:24<00:00,  4.43it/s, loss=0.9809, lr=1.0e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 완료, 평균 손실: 1.8774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|████████████████████████████████████████| 4893/4893 [17:38<00:00,  4.62it/s, loss=1.0610, lr=1.0e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 완료, 평균 손실: 1.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|████████████████████████████████████████| 4893/4893 [18:43<00:00,  4.36it/s, loss=1.3464, lr=9.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 완료, 평균 손실: 1.7710\n",
      "Epoch 5 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|████████████████████████████████████████| 4893/4893 [18:45<00:00,  4.35it/s, loss=2.5427, lr=9.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 완료, 평균 손실: 1.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|████████████████████████████████████████| 4893/4893 [18:41<00:00,  4.36it/s, loss=1.5224, lr=9.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 완료, 평균 손실: 1.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|████████████████████████████████████████| 4893/4893 [18:39<00:00,  4.37it/s, loss=2.1604, lr=9.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 완료, 평균 손실: 1.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|████████████████████████████████████████| 4893/4893 [18:41<00:00,  4.36it/s, loss=3.1603, lr=9.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 완료, 평균 손실: 1.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|███████████████████████████████████████| 4893/4893 [18:37<00:00,  4.38it/s, loss=1.3453, lr=9.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 완료, 평균 손실: 1.6041\n",
      "Epoch 10 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|███████████████████████████████████████| 4893/4893 [18:34<00:00,  4.39it/s, loss=1.0686, lr=9.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 완료, 평균 손실: 1.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|███████████████████████████████████████| 4893/4893 [18:29<00:00,  4.41it/s, loss=4.0620, lr=9.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 완료, 평균 손실: 1.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|███████████████████████████████████████| 4893/4893 [19:09<00:00,  4.26it/s, loss=1.6454, lr=9.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 완료, 평균 손실: 1.5305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.42it/s, loss=1.0336, lr=9.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 완료, 평균 손실: 1.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|███████████████████████████████████████| 4893/4893 [17:39<00:00,  4.62it/s, loss=1.2424, lr=9.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 완료, 평균 손실: 1.4860\n",
      "Epoch 15 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|███████████████████████████████████████| 4893/4893 [17:25<00:00,  4.68it/s, loss=1.1154, lr=9.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 완료, 평균 손실: 1.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|███████████████████████████████████████| 4893/4893 [17:45<00:00,  4.59it/s, loss=1.1489, lr=9.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 완료, 평균 손실: 1.4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|███████████████████████████████████████| 4893/4893 [18:36<00:00,  4.38it/s, loss=1.4512, lr=9.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 완료, 평균 손실: 1.4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|███████████████████████████████████████| 4893/4893 [18:48<00:00,  4.34it/s, loss=0.8112, lr=9.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 완료, 평균 손실: 1.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|███████████████████████████████████████| 4893/4893 [18:39<00:00,  4.37it/s, loss=1.0997, lr=9.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 완료, 평균 손실: 1.3857\n",
      "Epoch 20 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|███████████████████████████████████████| 4893/4893 [18:38<00:00,  4.37it/s, loss=2.5962, lr=9.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 완료, 평균 손실: 1.3634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|███████████████████████████████████████| 4893/4893 [18:37<00:00,  4.38it/s, loss=2.4981, lr=8.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 완료, 평균 손실: 1.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|███████████████████████████████████████| 4893/4893 [18:32<00:00,  4.40it/s, loss=1.3750, lr=8.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 완료, 평균 손실: 1.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=0.6480, lr=8.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 완료, 평균 손실: 1.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=2.8955, lr=8.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 완료, 평균 손실: 1.2976\n",
      "Epoch 25 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|███████████████████████████████████████| 4893/4893 [18:29<00:00,  4.41it/s, loss=1.3842, lr=8.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 완료, 평균 손실: 1.2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|███████████████████████████████████████| 4893/4893 [18:30<00:00,  4.41it/s, loss=0.6967, lr=8.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 완료, 평균 손실: 1.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.8149, lr=8.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 완료, 평균 손실: 1.2567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.42it/s, loss=1.5689, lr=8.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 완료, 평균 손실: 1.2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.4539, lr=7.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 완료, 평균 손실: 1.2308\n",
      "Epoch 30 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|███████████████████████████████████████| 4893/4893 [18:23<00:00,  4.44it/s, loss=3.2414, lr=7.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 완료, 평균 손실: 1.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|███████████████████████████████████████| 4893/4893 [18:24<00:00,  4.43it/s, loss=2.4743, lr=7.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 완료, 평균 손실: 1.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.9476, lr=7.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 완료, 평균 손실: 1.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.9691, lr=7.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 완료, 평균 손실: 1.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|███████████████████████████████████████| 4893/4893 [18:29<00:00,  4.41it/s, loss=0.9002, lr=7.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 완료, 평균 손실: 1.1632\n",
      "Epoch 35 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=0.8965, lr=7.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 완료, 평균 손실: 1.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|███████████████████████████████████████| 4893/4893 [18:29<00:00,  4.41it/s, loss=0.9731, lr=7.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 완료, 평균 손실: 1.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.43it/s, loss=5.2739, lr=6.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 완료, 평균 손실: 1.1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.5111, lr=6.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 완료, 평균 손실: 1.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.4417, lr=6.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 완료, 평균 손실: 1.1032\n",
      "Epoch 40 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.5538, lr=6.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 완료, 평균 손실: 1.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.4306, lr=6.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 완료, 평균 손실: 1.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.5390, lr=6.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 완료, 평균 손실: 1.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.42it/s, loss=2.2445, lr=5.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 완료, 평균 손실: 1.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.1685, lr=5.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 완료, 평균 손실: 1.0555\n",
      "Epoch 45 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=2.5082, lr=5.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 완료, 평균 손실: 1.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=2.5461, lr=5.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 완료, 평균 손실: 1.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=2.5293, lr=5.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 완료, 평균 손실: 1.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.6301, lr=5.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 완료, 평균 손실: 1.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.42it/s, loss=0.6305, lr=5.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 완료, 평균 손실: 1.0084\n",
      "Epoch 50 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.1390, lr=4.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 완료, 평균 손실: 1.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=0.8807, lr=4.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 완료, 평균 손실: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=0.7190, lr=4.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 완료, 평균 손실: 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.7631, lr=4.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 완료, 평균 손실: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.2794, lr=4.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 완료, 평균 손실: 0.9699\n",
      "Epoch 55 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|███████████████████████████████████████| 4893/4893 [19:37<00:00,  4.16it/s, loss=1.1147, lr=4.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 완료, 평균 손실: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|███████████████████████████████████████| 4893/4893 [19:00<00:00,  4.29it/s, loss=1.2258, lr=3.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 완료, 평균 손실: 0.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.0128, lr=3.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 완료, 평균 손실: 0.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.42it/s, loss=0.9237, lr=3.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 완료, 평균 손실: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|███████████████████████████████████████| 4893/4893 [18:28<00:00,  4.41it/s, loss=1.2282, lr=3.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 완료, 평균 손실: 0.9330\n",
      "Epoch 60 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=0.6195, lr=3.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 완료, 평균 손실: 0.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=0.9584, lr=3.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 완료, 평균 손실: 0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|███████████████████████████████████████| 4893/4893 [18:27<00:00,  4.42it/s, loss=1.5028, lr=3.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 완료, 평균 손실: 0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|███████████████████████████████████████| 4893/4893 [18:24<00:00,  4.43it/s, loss=0.4996, lr=2.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 완료, 평균 손실: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|███████████████████████████████████████| 4893/4893 [18:23<00:00,  4.43it/s, loss=0.9837, lr=2.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 완료, 평균 손실: 0.8999\n",
      "Epoch 65 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|███████████████████████████████████████| 4893/4893 [18:24<00:00,  4.43it/s, loss=2.6571, lr=2.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 완료, 평균 손실: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.42it/s, loss=1.1846, lr=2.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 완료, 평균 손실: 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.43it/s, loss=1.2869, lr=2.3e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 완료, 평균 손실: 0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.43it/s, loss=1.5141, lr=2.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 완료, 평균 손실: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.42it/s, loss=0.7361, lr=2.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 완료, 평균 손실: 0.8705\n",
      "Epoch 70 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|███████████████████████████████████████| 4893/4893 [18:26<00:00,  4.42it/s, loss=1.4559, lr=1.9e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 완료, 평균 손실: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|███████████████████████████████████████| 4893/4893 [18:25<00:00,  4.43it/s, loss=1.1051, lr=1.8e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 완료, 평균 손실: 0.8697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|███████████████████████████████████████| 4893/4893 [18:24<00:00,  4.43it/s, loss=3.4807, lr=1.7e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 완료, 평균 손실: 0.8643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|███████████████████████████████████████| 4893/4893 [18:23<00:00,  4.43it/s, loss=2.0520, lr=1.6e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 완료, 평균 손실: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|███████████████████████████████████████| 4893/4893 [17:52<00:00,  4.56it/s, loss=1.2008, lr=1.5e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 완료, 평균 손실: 0.8542\n",
      "Epoch 75 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|███████████████████████████████████████| 4893/4893 [18:44<00:00,  4.35it/s, loss=4.2947, lr=1.4e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 완료, 평균 손실: 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|███████████████████████████████████████| 4893/4893 [18:49<00:00,  4.33it/s, loss=2.3916, lr=1.2e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 완료, 평균 손실: 0.8503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|███████████████████████████████████████| 4893/4893 [17:45<00:00,  4.59it/s, loss=1.2802, lr=1.1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 완료, 평균 손실: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|███████████████████████████████████████| 4893/4893 [17:48<00:00,  4.58it/s, loss=0.7268, lr=1.0e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 완료, 평균 손실: 0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|███████████████████████████████████████| 4893/4893 [17:48<00:00,  4.58it/s, loss=0.7659, lr=9.5e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 완료, 평균 손실: 0.8357\n",
      "Epoch 80 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|███████████████████████████████████████| 4893/4893 [19:36<00:00,  4.16it/s, loss=0.7418, lr=8.6e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 완료, 평균 손실: 0.8301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|███████████████████████████████████████| 4893/4893 [18:16<00:00,  4.46it/s, loss=0.9073, lr=7.8e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 완료, 평균 손실: 0.8303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|███████████████████████████████████████| 4893/4893 [18:15<00:00,  4.47it/s, loss=1.6237, lr=7.0e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 완료, 평균 손실: 0.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|███████████████████████████████████████| 4893/4893 [20:15<00:00,  4.02it/s, loss=0.6719, lr=6.2e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 완료, 평균 손실: 0.8225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|███████████████████████████████████████| 4893/4893 [18:49<00:00,  4.33it/s, loss=1.6057, lr=5.4e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 완료, 평균 손실: 0.8218\n",
      "Epoch 85 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|███████████████████████████████████████| 4893/4893 [18:44<00:00,  4.35it/s, loss=1.3206, lr=4.8e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 완료, 평균 손실: 0.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|███████████████████████████████████████| 4893/4893 [18:29<00:00,  4.41it/s, loss=4.4359, lr=4.1e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 완료, 평균 손실: 0.8181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|███████████████████████████████████████| 4893/4893 [17:53<00:00,  4.56it/s, loss=1.4054, lr=3.5e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 완료, 평균 손실: 0.8184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|███████████████████████████████████████| 4893/4893 [18:06<00:00,  4.50it/s, loss=0.7374, lr=3.0e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 완료, 평균 손실: 0.8165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|███████████████████████████████████████| 4893/4893 [18:21<00:00,  4.44it/s, loss=0.9778, lr=2.4e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 완료, 평균 손실: 0.8133\n",
      "Epoch 90 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|███████████████████████████████████████| 4893/4893 [18:21<00:00,  4.44it/s, loss=1.2163, lr=2.0e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 완료, 평균 손실: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|███████████████████████████████████████| 4893/4893 [18:06<00:00,  4.50it/s, loss=0.7538, lr=1.6e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 완료, 평균 손실: 0.8116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|███████████████████████████████████████| 4893/4893 [18:33<00:00,  4.39it/s, loss=1.4849, lr=1.2e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 완료, 평균 손실: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|███████████████████████████████████████| 4893/4893 [18:33<00:00,  4.39it/s, loss=0.8543, lr=8.9e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 완료, 평균 손실: 0.8118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|███████████████████████████████████████| 4893/4893 [18:39<00:00,  4.37it/s, loss=1.1809, lr=6.2e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 완료, 평균 손실: 0.8116\n",
      "Epoch 95 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|███████████████████████████████████████| 4893/4893 [18:42<00:00,  4.36it/s, loss=0.8691, lr=3.9e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 완료, 평균 손실: 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|███████████████████████████████████████| 4893/4893 [18:13<00:00,  4.48it/s, loss=1.0428, lr=2.2e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 완료, 평균 손실: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|███████████████████████████████████████| 4893/4893 [18:31<00:00,  4.40it/s, loss=0.8952, lr=9.9e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 완료, 평균 손실: 0.8127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|███████████████████████████████████████| 4893/4893 [18:33<00:00,  4.39it/s, loss=1.4572, lr=2.5e-08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 완료, 평균 손실: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████████████████████████████████| 4893/4893 [18:35<00:00,  4.39it/s, loss=0.9170, lr=0.0e+00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 완료, 평균 손실: 0.8122\n",
      "Epoch 100 모델 저장 완료.\n",
      "학습이 모두 완료되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#detection\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 증강 및 기하학 라이브러리\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pyclipper\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 1: 데이터 파이프라인 (Dataset, Augmentation, Ground Truth 생성)\n",
    "\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 1: 데이터 파이프라인 (최종 수정된 OcrDataset 클래스)\n",
    "\n",
    "\n",
    "class OcrDataset(Dataset):\n",
    "    def __init__(self, annotation_path, image_dir, transform=None, target_size=640):\n",
    "        super().__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # [수정] 1. JSON 파일을 열고 전체 데이터를 로드합니다.\n",
    "        print(\"어노테이션 파일을 로드하고 데이터를 전처리합니다...\")\n",
    "        with open(annotation_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # [수정] 2. 나중에 데이터를 빠르게 찾기 위해 Dictionary 형태로 정보를 가공합니다.\n",
    "        # image_id를 key로, 이미지 정보를 value로 하는 딕셔너리 생성\n",
    "        self.image_infos = {img['id']: img for img in data['images']}\n",
    "        \n",
    "        # image_id를 key로, 해당 이미지의 어노테이션 리스트를 value로 하는 딕셔너리 생성\n",
    "        self.annotations_by_image_id = {}\n",
    "        for ann in data['annotations']:\n",
    "            image_id = ann['image_id']\n",
    "            if image_id not in self.annotations_by_image_id:\n",
    "                self.annotations_by_image_id[image_id] = []\n",
    "            self.annotations_by_image_id[image_id].append(ann)\n",
    "\n",
    "        # [수정] 3. 실제 어노테이션이 존재하는 이미지들의 ID만 리스트로 만듭니다.\n",
    "        # 이것이 우리 데이터셋의 실제 목록이 됩니다.\n",
    "        self.image_ids = [img_id for img_id in self.image_infos.keys() if img_id in self.annotations_by_image_id]\n",
    "        print(f\"총 {len(self.image_ids)}개의 유효한 이미지를 찾았습니다.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 전체 길이는 유효한 이미지 ID의 개수입니다.\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def _bbox_to_polygon(self, bbox):\n",
    "        \"\"\" [새로운 기능] Bbox [x, y, w, h]를 폴리곤 [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]으로 변환합니다. \"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        return [[x, y], [x + w, y], [x + w, y + h], [x, y + h]]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        for _ in range(len(self)):\n",
    "            try:\n",
    "                image_id = self.image_ids[idx]\n",
    "                image_info = self.image_infos[image_id]\n",
    "                annotations = self.annotations_by_image_id[image_id]\n",
    "                image_path = os.path.join(self.image_dir, image_info['file_name'])\n",
    "    \n",
    "                img_array = np.fromfile(image_path, np.uint8)\n",
    "                image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "                if image is None:\n",
    "                    raise IOError(f\"이미지 디코딩 실패: {image_path}\")\n",
    "                \n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # ========================= [최종 수정 핵심] =========================\n",
    "                # bbox가 존재하고, 4개의 값을 가지며, 너비(w)와 높이(h)가 0보다 큰 경우에만 처리합니다.\n",
    "                # ann['bbox'][2]가 너비(w), ann['bbox'][3]이 높이(h)에 해당합니다.\n",
    "                polygons = [\n",
    "                    np.array(self._bbox_to_polygon(ann['bbox'])) \n",
    "                    for ann in annotations \n",
    "                    if ann.get('bbox') and len(ann.get('bbox')) == 4 and ann['bbox'][2] > 0 and ann['bbox'][3] > 0\n",
    "                ]\n",
    "                # =================================================================\n",
    "    \n",
    "                if not polygons:\n",
    "                    # 유효한 bbox가 하나도 없는 경우, 이 이미지는 건너뜁니다.\n",
    "                    raise ValueError(\"유효한 Bbox 없음\")\n",
    "    \n",
    "                points_for_aug = [point for poly in polygons for point in poly]\n",
    "                \n",
    "                if self.transform:\n",
    "                    transformed = self.transform(image=image, keypoints=points_for_aug)\n",
    "                    image = transformed['image']\n",
    "                    \n",
    "                    transformed_polygons_temp = []\n",
    "                    start = 0\n",
    "                    for poly in polygons:\n",
    "                        num_points = len(poly)\n",
    "                        transformed_poly = transformed['keypoints'][start : start + num_points]\n",
    "                        transformed_polygons_temp.append(np.array(transformed_poly, dtype=np.float32))\n",
    "                        start += num_points\n",
    "                    \n",
    "                    # 데이터 증강 후 비어있거나 유효하지 않은 폴리곤을 최종적으로 제거합니다.\n",
    "                    polygons = [p for p in transformed_polygons_temp if len(p) > 2]\n",
    "                    \n",
    "                    if not polygons:\n",
    "                        raise ValueError(\"증강 후 유효한 폴리곤 없음\")\n",
    "                else:\n",
    "                    polygons = [p.astype(np.float32) for p in polygons]\n",
    "    \n",
    "                gt_prob_map, gt_prob_mask, gt_thresh_map, gt_thresh_mask = self.make_db_ground_truth(\n",
    "                    polygons, self.target_size, self.target_size\n",
    "                )\n",
    "                \n",
    "                # 모든 처리에 성공했으면 결과를 반환하고 루프를 빠져나갑니다.\n",
    "                return image, gt_prob_map, gt_prob_mask, gt_thresh_map, gt_thresh_mask\n",
    "    \n",
    "            except Exception as e:\n",
    "                # 문제가 발생하면 다음 인덱스를 시도합니다.\n",
    "                try:\n",
    "                    fname = image_info['file_name']\n",
    "                except NameError:\n",
    "                    fname = \"알 수 없음\"\n",
    "                \n",
    "                print(f\"경고: 인덱스 {idx} 처리 중 오류 발생 ('{fname}'): {e}, 다음 샘플로 넘어갑니다.\")\n",
    "                idx = (idx + 1) % len(self)\n",
    "        \n",
    "        # 모든 데이터를 시도했지만 유효한 데이터를 찾지 못한 경우\n",
    "        raise RuntimeError(\"데이터셋에서 유효한 샘플을 하나도 찾지 못했습니다.\")\n",
    "\n",
    "\n",
    "\n",
    "    # make_db_ground_truth 함수는 이전과 동일하게 사용하면 됩니다.\n",
    "    def make_db_ground_truth(self, polygons, height, width):\n",
    "        gt_prob_map = np.zeros((height, width), dtype=np.float32)\n",
    "        gt_prob_mask = np.ones((height, width), dtype=np.float32)\n",
    "        gt_thresh_map = np.zeros((height, width), dtype=np.float32)\n",
    "        gt_thresh_mask = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "        for polygon in polygons:\n",
    "            # ========================= [디버깅 코드 추가] =========================\n",
    "            # cv2.contourArea 함수를 호출하기 전에, 어떤 데이터로 호출하는지 확인합니다.\n",
    "            # 문제가 발생하면 어떤 데이터가 범인인지 알 수 있습니다.\n",
    "            try:\n",
    "                # 1. 면적을 먼저 계산해 봅니다.\n",
    "                area = cv2.contourArea(polygon)\n",
    "                \n",
    "                # 2. 면적이 0보다 작거나 같으면 (선 또는 점이면) 건너뜁니다.\n",
    "                if area <= 0:\n",
    "                    continue\n",
    "    \n",
    "                # 3. 둘레를 계산합니다.\n",
    "                perimeter = cv2.arcLength(polygon, True)\n",
    "                if perimeter == 0:\n",
    "                    continue\n",
    "            \n",
    "            except Exception as e:\n",
    "                # 만약 cv2.contourArea 자체에서 오류가 발생한다면,\n",
    "                # 어떤 데이터가 문제를 일으켰는지 출력하고 건너뜁니다.\n",
    "                print(\"\\n\" + \"=\"*20)\n",
    "                print(\"[디버깅] cv2.contourArea 에서 오류 발생! 아래 데이터를 확인하세요.\")\n",
    "                print(f\"문제가 발생한 폴리곤: {polygon}\")\n",
    "                print(f\"폴리곤의 shape: {polygon.shape}\")\n",
    "                print(f\"폴리곤의 dtype: {polygon.dtype}\")\n",
    "                print(f\"오류 내용: {e}\")\n",
    "                print(\"=\"*20 + \"\\n\")\n",
    "                continue\n",
    "            # ====================================================================\n",
    "                \n",
    "            polygon = np.clip(polygon, [0, 0], [width - 1, height - 1])\n",
    "            \n",
    "            cv2.fillPoly(gt_prob_map, [polygon.astype(np.int32)], 1.0)\n",
    "            \n",
    "            pco = pyclipper.PyclipperOffset()\n",
    "            pco.AddPath(polygon.tolist(), pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n",
    "            \n",
    "            distance = area * (1 - 0.4**2) / (perimeter + 1e-6)\n",
    "            shrunk_polygons = pco.Execute(-distance)\n",
    "            \n",
    "            if not shrunk_polygons: continue\n",
    "            \n",
    "            cv2.fillPoly(gt_thresh_mask, [np.array(p).astype(np.int32) for p in shrunk_polygons], 1.0)\n",
    "    \n",
    "        dist_map = cv2.distanceTransform(gt_prob_map.astype(np.uint8), cv2.DIST_L2, 5)\n",
    "        \n",
    "        min_val, max_val = np.min(dist_map), np.max(dist_map)\n",
    "        if max_val > min_val:\n",
    "            dist_map = (dist_map - min_val) / (max_val - min_val)\n",
    "        \n",
    "        gt_thresh_map = dist_map * gt_thresh_mask\n",
    "        \n",
    "        return (torch.from_numpy(gt_prob_map).unsqueeze(0),\n",
    "                torch.from_numpy(gt_prob_mask).unsqueeze(0),\n",
    "                torch.from_numpy(gt_thresh_map).unsqueeze(0),\n",
    "                torch.from_numpy(gt_thresh_mask).unsqueeze(0))\n",
    "\n",
    "def get_transforms(size):\n",
    "    \n",
    "    return A.Compose([\n",
    "        A.Resize(size, size, always_apply=True),\n",
    "        A.Rotate(limit=10, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.ColorJitter(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "# ====================================================================================\n",
    "# Part 2: 모델 및 손실 함수 아키텍처\n",
    "# ====================================================================================\n",
    "class MobileNetV3_Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        # mobilenet_v3_large의 특징 추출기 부분을 가져옵니다.\n",
    "        self.features = mobilenet_v3_large(weights='IMAGENET1K_V1' if pretrained else None).features\n",
    "        \n",
    "        # FPN으로 특징을 전달할 레이어의 인덱스를 지정합니다.\n",
    "        # 이 인덱스는 MobileNetV3-Large의 구조에 따릅니다.\n",
    "        self.output_indices = [3, 6, 12, 16]\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        # features 모듈을 순차적으로 통과시키며, 지정된 인덱스에서 출력을 저장합니다.\n",
    "        for i, layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            if i in self.output_indices:\n",
    "                outputs.append(x)\n",
    "        return outputs\n",
    "\n",
    "class DB_FPN(nn.Module):\n",
    "    # MobileNetV3-Large의 실제 출력 채널에 맞게 기본값을 수정합니다.\n",
    "    def __init__(self, in_channels=[24, 40, 112, 960], out_channels=256):\n",
    "        super().__init__()\n",
    "        self.in_convs = nn.ModuleList([nn.Conv2d(c, out_channels, 1, bias=False) for c in in_channels])\n",
    "        self.out_convs = nn.ModuleList([nn.Conv2d(out_channels, out_channels // 4, 3, padding=1, bias=False) for _ in in_channels])\n",
    "\n",
    "    def forward(self, features):\n",
    "        # features의 순서는 [C2, C3, C4, C5] 입니다. (작은 것 -> 큰 것)\n",
    "        c2, c3, c4, c5 = features\n",
    "\n",
    "        # 입력 채널에 맞게 1x1 conv 적용\n",
    "        in5 = self.in_convs[3](c5)\n",
    "        in4 = self.in_convs[2](c4)\n",
    "        in3 = self.in_convs[1](c3)\n",
    "        in2 = self.in_convs[0](c2)\n",
    "\n",
    "        # Top-down 경로 (FPN의 핵심)\n",
    "        out4 = in4 + F.interpolate(in5, size=in4.shape[2:], mode='bilinear', align_corners=False) # P5 -> P4\n",
    "        out3 = in3 + F.interpolate(out4, size=in3.shape[2:], mode='bilinear', align_corners=False) # P4 -> P3\n",
    "        out2 = in2 + F.interpolate(out3, size=in2.shape[2:], mode='bilinear', align_corners=False) # P3 -> P2\n",
    "\n",
    "        # 3x3 conv로 최종 특징 맵 생성 및 업샘플링 후 합치기\n",
    "        p5 = F.interpolate(self.out_convs[3](in5), size=out2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        p4 = F.interpolate(self.out_convs[2](out4), size=out2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        p3 = F.interpolate(self.out_convs[1](out3), size=out2.shape[2:], mode='bilinear', align_corners=False)\n",
    "        p2 = self.out_convs[0](out2)\n",
    "        \n",
    "        return torch.cat([p2, p3, p4, p5], dim=1)\n",
    "\n",
    "# DB_Head, DBNet, DiceLoss, DBLoss 클래스는 수정할 필요가 없습니다.\n",
    "# (기존 코드 그대로 사용)\n",
    "class DB_Head(nn.Module):\n",
    "    def __init__(self, in_channels=256):\n",
    "        super().__init__()\n",
    "        # [수정] 최종 출력이 640x640이 되도록 nn.Upsample 레이어를 추가합니다.\n",
    "        self.prob_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 4, 3, padding=1), \n",
    "            nn.BatchNorm2d(in_channels // 4), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(in_channels // 4, 1, 2, 2), # 여기까지 출력이 320x320\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # 320x320 -> 640x640\n",
    "        )\n",
    "        self.thresh_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 4, 3, padding=1), \n",
    "            nn.BatchNorm2d(in_channels // 4), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(in_channels // 4, 1, 2, 2), # 여기까지 출력이 320x320\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # 320x320 -> 640x640\n",
    "        )\n",
    "    def forward(self, x): \n",
    "        return torch.sigmoid(self.prob_conv(x)), torch.sigmoid(self.thresh_conv(x))\n",
    "\n",
    "\n",
    "class DBNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.backbone = MobileNetV3_Backbone(pretrained)\n",
    "        self.fpn = DB_FPN()\n",
    "        self.head = DB_Head()\n",
    "    def forward(self, x): return self.head(self.fpn(self.backbone(x)))\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__(); self.eps = eps\n",
    "    def forward(self, pred, target, mask):\n",
    "        pred, target = pred * mask, target * mask; intersection = (pred * target).sum()\n",
    "        union = pred.sum() + target.sum() + self.eps; return 1 - (2 * intersection / union)\n",
    "\n",
    "class DBLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, beta=10.0, k=50):\n",
    "        super().__init__(); self.alpha, self.beta, self.k = alpha, beta, k\n",
    "        self.bce_loss = nn.BCELoss(reduction='none'); self.dice_loss = DiceLoss()\n",
    "    def forward(self, pred_maps, gt_maps):\n",
    "        pred_prob, pred_thresh = pred_maps; gt_prob, gt_prob_mask, gt_thresh, gt_thresh_mask = gt_maps\n",
    "        loss_s = self.dice_loss(pred_prob, gt_prob, gt_prob_mask) + (self.bce_loss(pred_prob, gt_prob) * gt_prob_mask).mean()\n",
    "        db_map = 1 / (1 + torch.exp(-self.k * (pred_prob - pred_thresh)))\n",
    "        loss_b = self.dice_loss(db_map, gt_prob, gt_prob_mask)\n",
    "        loss_t = (torch.abs(pred_thresh - gt_thresh) * gt_thresh_mask).sum() / (gt_thresh_mask.sum() + 1e-6)\n",
    "        return loss_s + self.alpha * loss_b + self.beta * loss_t\n",
    "\n",
    "# ====================================================================================\n",
    "# Part 3: 실제 학습 스크립트\n",
    "# ====================================================================================\n",
    "def main():\n",
    "    # --- 1. 설정 (사용자 환경에 맞게 수정) ---\n",
    "    # 이 경로들을 자신의 데이터셋 경로로 반드시 수정해야 합니다.\n",
    "    ANNOTATION_PATH = r\"D:\\ocr_project\\DBnet_OCR\\data\\textinthewild_data_info_cleaned.json\"\n",
    "    IMAGE_DIR = r\"D:\\ocr_project\\DBnet_OCR\\data\\01_textinthewild_book_images_new\\01_textinthewild_book_images_new\\book\"\n",
    "    \n",
    "    # 하이퍼파라미터\n",
    "    IMG_SIZE = 640\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCHS = 100 # 실제 학습을 위해 Epoch 수를 늘립니다.\n",
    "    LEARNING_RATE = 1e-4\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    print(f\"사용 장치: {DEVICE}\")\n",
    "    print(\"사전 학습된 MobileNetV3 가중치를 사용합니다.\")\n",
    "\n",
    "    # --- 2. 데이터 파이프라인 준비 ---\n",
    "    print(\"데이터 로더를 준비합니다...\")\n",
    "    try:\n",
    "        dataset = OcrDataset(\n",
    "            annotation_path=ANNOTATION_PATH,\n",
    "            image_dir=IMAGE_DIR,\n",
    "            transform=get_transforms(IMG_SIZE)\n",
    "        )\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers = 0  # CPU 코어 수에 맞게 조절\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"오류: 데이터셋 경로를 찾을 수 없습니다. ANNOTATION_PATH와 IMAGE_DIR을 확인하세요.\")\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    # --- 3. 모델, 손실함수, 옵티마이저 준비 ---\n",
    "    print(\"모델과 옵티마이저를 준비합니다...\")\n",
    "    detector = DBNet(pretrained=True).to(DEVICE)\n",
    "    db_loss_fn = DBLoss().to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(detector.parameters(), lr=LEARNING_RATE) # AdamW가 종종 더 나은 성능을 보임\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(data_loader) * NUM_EPOCHS)\n",
    "\n",
    "    # --- 4. 학습 루프 ---\n",
    "    print(\"학습을 시작합니다...\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        detector.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        for batch_idx, (images, gt_prob, gt_prob_mask, gt_thresh, gt_thresh_mask) in enumerate(progress_bar):\n",
    "            images = images.to(DEVICE)\n",
    "            gt_prob, gt_prob_mask = gt_prob.to(DEVICE), gt_prob_mask.to(DEVICE)\n",
    "            gt_thresh, gt_thresh_mask = gt_thresh.to(DEVICE), gt_thresh_mask.to(DEVICE)\n",
    "            \n",
    "            pred_prob, pred_thresh = detector(images)\n",
    "            loss = db_loss_fn((pred_prob, pred_thresh), (gt_prob, gt_prob_mask, gt_thresh, gt_thresh_mask))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step() # 매 스텝마다 학습률 조절\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{scheduler.get_last_lr()[0]:.1e}\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(data_loader)\n",
    "        print(f\"Epoch {epoch+1} 완료, 평균 손실: {avg_loss:.4f}\")\n",
    "\n",
    "        # --- 5. 체크포인트 저장 ---\n",
    "        if (epoch + 1) % 5 == 0: # 5 에포크마다 저장\n",
    "            torch.save(detector.state_dict(), f\"dbnet_detector_epoch_{epoch+1}.pth\")\n",
    "            print(f\"Epoch {epoch+1} 모델 저장 완료.\")\n",
    "\n",
    "    print(\"학습이 모두 완료되었습니다.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7870929-44ab-41c0-8d3f-717fc4cb0412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (OCR Project)",
   "language": "python",
   "name": "ocr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
